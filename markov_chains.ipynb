{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/franciscofurey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differents approaches of Markov Chains\n",
    "\n",
    "### Using as example the menu of a restauran (burger, pizza and hotdog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State representation\n",
    "def get_states() -> dict:\n",
    "    \"\"\"Return the mapping of state indices to state names.\"\"\"\n",
    "    return {\n",
    "        0: \"Burger\",\n",
    "        1: \"Pizza\",\n",
    "        2: \"Hotdog\"\n",
    "    }\n",
    "\n",
    "# Transition Matrix\n",
    "def get_transition_matrix() -> np.ndarray:\n",
    "    \"\"\"Return the transition matrix A.\"\"\"\n",
    "    return np.array([[0.2, 0.6, 0.2], [0.3, 0.0, 0.7], [0.5, 0.0, 0.5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(start_state: int, steps: int) -> None:\n",
    "    \"\"\"Perform a random walk on the Markov chain given a start state and number of steps.\"\"\"\n",
    "    \n",
    "    A = get_transition_matrix()  # Retrieve the transition matrix for the Markov chain\n",
    "    state = get_states()  # Get the possible states in the Markov chain\n",
    "    curr_state = start_state  # Initialize the current state with the start state\n",
    "    print(state[curr_state], \"--->\", end=\" \")  # Print the start state\n",
    "    \n",
    "    while steps - 1:  # Continue the walk until the desired number of steps is reached\n",
    "        curr_state = np.random.choice([0, 1, 2], p=A[curr_state])  # Choose the next state based on the current state's transition probabilities\n",
    "        print(state[curr_state], \"--->\", end=\" \")  # Print the current state after each step\n",
    "        steps -= 1  # Decrement the steps counter\n",
    "    print(\"stop\")  # Indicate that the walk has stopped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(start_state: int, steps: int) -> None:\n",
    "    \"\"\"Estimate steady state probabilities using the Monte Carlo approach.\"\"\"\n",
    "    \n",
    "    A = get_transition_matrix()  # Retrieve the transition matrix for the Markov chain\n",
    "    curr_state = start_state  # Initialize the current state with the start state\n",
    "    pi = np.array([0, 0, 0])  # Initialize a vector to count the visits to each state\n",
    "    pi[start_state] = 1  # Start by marking the initial state as visited once\n",
    "\n",
    "    for i in range(steps):  # Iterate through the number of steps\n",
    "        curr_state = np.random.choice([0, 1, 2], p=A[curr_state])  # Choose the next state based on current state's transition probabilities\n",
    "        pi[curr_state] += 1  # Increment the count for the visited state\n",
    "\n",
    "    print(\"π = \", pi / steps)  # Calculate and print the estimated steady state probabilities by normalizing the counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_matrix_multiplication(steps: int) -> None:\n",
    "    \"\"\"Calculate steady state probabilities using repeated matrix multiplication.\"\"\"\n",
    "    \n",
    "    A = get_transition_matrix()  # Retrieve the transition matrix for the Markov chain\n",
    "    A_n = A  # Initialize A_n with the transition matrix A for multiplication\n",
    "\n",
    "    for i in range(steps):  # Loop through the specified number of steps\n",
    "        A_n = np.matmul(A_n, A)  # Multiply the current A_n by A to get the next A_n\n",
    "\n",
    "    print(\"A^n = \\n\", A_n, \"\\n\")  # Print the matrix after n multiplications\n",
    "    print(\"π = \", A_n[0])  # The first row of A^n approximates the steady state probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_left_eigen_vectors() -> None:\n",
    "    \"\"\"Find and display left eigen vectors and their normalized steady state probabilities.\"\"\"\n",
    "    \n",
    "    A = get_transition_matrix()  # Retrieve the transition matrix for the Markov chain\n",
    "    values, left = scipy.linalg.eig(A, right=False, left=True)  # Compute the left eigenvectors and eigenvalues of the transition matrix A\n",
    "\n",
    "    print(\"left eigen vectors = \\n\", left, \"\\n\")  # Print the left eigenvectors\n",
    "    print(\"eigen values = \\n\", values)  # Print the eigenvalues\n",
    "\n",
    "    pi = left[:, 0]  # Extract the first left eigenvector, which corresponds to the steady state\n",
    "    pi_normalized = [(x / np.sum(pi)).real for x in pi]  # Normalize the first left eigenvector to get steady state probabilities\n",
    "    \n",
    "    print(\"Normalized π = \", pi_normalized)  # Print the normalized steady state probabilities\n",
    "    return pi_normalized  # Return the normalized steady state probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prob(seq: list, A: np.ndarray, pi: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the probability of a given sequence of states in a Markov chain.\n",
    "\n",
    "    Parameters:\n",
    "    - seq: The sequence of states.\n",
    "    - A: The transition matrix of the Markov chain.\n",
    "    - pi: The initial state probabilities.\n",
    "\n",
    "    Returns:\n",
    "    - The probability of observing the given sequence of states.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_state = seq[0]  # Extract the starting state from the sequence\n",
    "    prob = pi[start_state]  # Initialize the probability with the initial probability of the start state\n",
    "    \n",
    "    prev_state = start_state  # Set the previous state as the start state for iteration\n",
    "    for i in range(1, len(seq)):  # Iterate through the sequence starting from the second state\n",
    "        curr_state = seq[i]  # Current state in the sequence\n",
    "        prob *= A[prev_state][curr_state]  # Multiply the current probability by the transition probability from the previous state to the current state\n",
    "        prev_state = curr_state  # Update the previous state for the next iteration\n",
    "    \n",
    "    return prob  # Return the calculated probability of the sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burger ---> Pizza ---> Burger ---> Pizza ---> Hotdog ---> Burger ---> Burger ---> Burger ---> Pizza ---> Hotdog ---> Hotdog ---> Burger ---> Pizza ---> Burger ---> Pizza ---> stop\n",
      "π =  [0.352207 0.211071 0.436723]\n",
      "A^n = \n",
      " [[0.35211268 0.21126761 0.43661972]\n",
      " [0.35211268 0.21126761 0.43661972]\n",
      " [0.35211268 0.21126761 0.43661972]] \n",
      "\n",
      "π =  [0.35211268 0.21126761 0.43661972]\n",
      "left eigen vectors = \n",
      " [[-0.58746336+0.j         -0.16984156-0.35355339j -0.16984156+0.35355339j]\n",
      " [-0.35247801+0.j          0.67936622+0.j          0.67936622-0.j        ]\n",
      " [-0.72845456+0.j         -0.50952467+0.35355339j -0.50952467-0.35355339j]] \n",
      "\n",
      "eigen values = \n",
      " [ 1.  +0.j        -0.15+0.3122499j -0.15-0.3122499j]\n",
      "Normalized π =  [0.3521126760563379, 0.2112676056338029, 0.43661971830985913]\n",
      "Sequence Probability:  0.036971830985915506\n"
     ]
    }
   ],
   "source": [
    "# Initial setup\n",
    "states = get_states()\n",
    "transition_matrix = get_transition_matrix()\n",
    "\n",
    "# Perform a random walk\n",
    "random_walk(start_state=0, steps=15)\n",
    "\n",
    "# Monte Carlo approach\n",
    "monte_carlo(start_state=0, steps=10**6)\n",
    "\n",
    "# Repeated matrix multiplication\n",
    "repeated_matrix_multiplication(steps=10**3)\n",
    "\n",
    "# Find left eigen vectors and their normalized steady state probabilities\n",
    "pi_normalized = find_left_eigen_vectors()\n",
    "\n",
    "# Calculate probability for a sequence\n",
    "sequence_prob = find_prob(seq=[1, 2, 2, 0], A=transition_matrix, pi=pi_normalized)\n",
    "print(\"Sequence Probability: \", sequence_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sherlock Holmes Example ussing Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines =  215021\n",
      "Number of words =  2332247\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the directory containing the stories.\n",
    "story_path = './data/sherlock/sherlock/'\n",
    "\n",
    "def read_all_stories(story_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Reads all text files from a specified directory, stopping at a delimiter or an empty line.\n",
    "    \n",
    "    Parameters:\n",
    "        story_path (str): The path to the directory containing story files.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of lines from all files, excluding delimiter lines and empty lines.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for _, _, files in os.walk(story_path):\n",
    "        for file in files:\n",
    "            with open(os.path.join(story_path, file)) as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line == '----------': break\n",
    "                    if line:\n",
    "                        lines.append(line)\n",
    "    return lines\n",
    "        \n",
    "stories = read_all_stories(story_path=story_path)\n",
    "print(\"Number of lines = \", len(stories))\n",
    "\n",
    "def clean_txt(txt: list) -> list:\n",
    "    \"\"\"\n",
    "    Cleans a list of text lines by converting to lowercase, removing punctuation, and tokenizing.\n",
    "    \n",
    "    Parameters:\n",
    "        txt (list): A list of text lines to be cleaned.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of cleaned and tokenized words.\n",
    "    \"\"\"\n",
    "    cleaned_words = []\n",
    "    for line in txt:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\\\[\\]]\", \"\", line)\n",
    "        tokens = word_tokenize(line)\n",
    "        # Filter out tokens that are not alphabetic\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_words += words\n",
    "    return cleaned_words\n",
    "\n",
    "cleaned_stories = clean_txt(txt=stories)\n",
    "print(\"Number of words = \", len(cleaned_stories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states =  208717\n",
      "All possible transitions from 'the game' state: \n",
      "\n",
      "{'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'was afoot': 0.036036036036036036, 'for the': 0.036036036036036036, 'was whist': 0.036036036036036036, 'would have': 0.036036036036036036, 'in their': 0.036036036036036036, 'was up': 0.09009009009009009, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'is afoot': 0.036036036036036036, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703, 'your letter': 0.02702702702702703}\n"
     ]
    }
   ],
   "source": [
    "def make_markov_model(cleaned_stories: list, n_gram: int = 2) -> dict:\n",
    "    \"\"\"\n",
    "    Constructs a Markov model from a list of words.\n",
    "\n",
    "    This function creates a dictionary representing the transitions between n-gram states\n",
    "    to the next possible states along with their probabilities.\n",
    "\n",
    "    Parameters:\n",
    "        cleaned_stories (list): A list of cleaned and tokenized words from stories.\n",
    "        n_gram (int): The number of words in the state used for the Markov model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the Markov model where keys are current states\n",
    "              and values are dictionaries of next possible states and their probabilities.\n",
    "    \"\"\"\n",
    "    markov_model = {}  # Initialize an empty dictionary for the Markov model\n",
    "\n",
    "    # Loop through the list of words to populate the Markov model\n",
    "    for i in range(len(cleaned_stories) - n_gram - 1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        # Construct the current and next state by concatenating words\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]  # Remove the trailing space\n",
    "        next_state = next_state[:-1]\n",
    "\n",
    "        # If the current state is not in the model, add it\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {next_state: 1}\n",
    "        else:\n",
    "            # If the next state exists, increment; otherwise, add it with a count of 1\n",
    "            markov_model[curr_state].setdefault(next_state, 0)\n",
    "            markov_model[curr_state][next_state] += 1\n",
    "    \n",
    "    # Calculate transition probabilities for each state\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count / total  # Convert counts to probabilities\n",
    "        \n",
    "    return markov_model\n",
    "\n",
    "# Example usage\n",
    "markov_model = make_markov_model(cleaned_stories=cleaned_stories)\n",
    "print(\"Number of states = \", len(markov_model.keys()))\n",
    "print(\"All possible transitions from 'the game' state: \\n\")\n",
    "if 'the game' in markov_model:\n",
    "    print(markov_model['the game'])\n",
    "else:\n",
    "    print(\"The state 'the game' does not exist in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. dear holmes it is again he had lit his pipe to emphasize each curious episode in comparison with\n",
      "1. dear holmes said i it is curious is it not been for my dear fellow he is when\n",
      "2. dear holmes my previous letters and having applied the rules of this said he in a cab if\n",
      "3. dear holmes i ejaculated oh there can be little doubt that the faintest shadow of a sentence he\n",
      "4. dear holmes what do you deduce that this good gentleman mr holmes i wished to live in order\n",
      "5. dear holmes i fear that youll let me advise you as to the admiralty chief secretary of the\n",
      "6. dear holmes he has gone come with me you must admit that what you were after two days\n",
      "7. dear holmes i exclaimed you will send for your friend this was raving insanity he shuddered and again\n",
      "8. dear holmes am i allowed to cooperate with him and wasnt it natural also that i should study\n",
      "9. dear holmes oh yes you have heard of there you may be of some club friends opposite to\n",
      "10. dear holmes that i can add anything which will cover the facts they are in this matter it\n",
      "11. dear holmes i thought you were in a pink dressing gown which covered his night clothes nothing had\n",
      "12. dear holmes am i he gazed about him he was safe with us if i dared to say\n",
      "13. dear holmes it is because it is frayed he was to expose himself and his emotions and yours\n",
      "14. dear holmes i exclaimed devoutly but you were told to receive all orders for and for a moment\n",
      "15. dear holmes he has had his mate scanlan not been robbed and beaten and abused because i have\n",
      "16. dear holmes he has to be determined is whether we have anything that is the exact purpose was\n",
      "17. dear holmes you are all on causes and inferences and effects in the bishopgate jewel case its true\n",
      "18. dear holmes said i you have evidence that he maintained a continual watch over foreigners in england the\n",
      "19. dear holmes he has definitely retired from london to inquire about twelve ah then you must have examined\n",
      "-------------------\n",
      "A longer story:\n",
      "the case with a gold chain five sovereigns in gold and seven hundred in notes he said holmes taking a clean white cloth from a drawer which they carried proclaimed themselves miners these sat smoking in silence i heard that he was a man that reached out his long arm to turn the stone is he here because an illustrious client has introduced us to what this might be the more worthy of being ruined my good sir said sherlock holmes in that case you can hear what you have told us as much as pa so then i locked up the curtain when i got back after some persuasion upon the spot the same afternoon brought a pack of cards in his hand it gave a metallic clang which might have been easier but you spoke of the pace there can be no difficulty in perceiving the drift of spray and a bird to be careful for we have a fresh crop of livid fungi was growing under it but never quite so he answered then what are they now in considering this case there is neither money nor credit in i dont understand it admits that she had them the\n"
     ]
    }
   ],
   "source": [
    "def generate_story(markov_model: dict, limit: int = 100, start: str = 'my god') -> str:\n",
    "    \"\"\"\n",
    "    Generates a story based on a given Markov model, starting from a specified state.\n",
    "\n",
    "    Parameters:\n",
    "        markov_model (dict): The Markov model to use for generating the story.\n",
    "        limit (int): The maximum number of words in the generated story.\n",
    "        start (str): The starting state (words) for the story.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the generated story.\n",
    "    \"\"\"\n",
    "    n = 0  # Initialize word counter\n",
    "    curr_state = start  # Set the current state to the starting words\n",
    "    story = curr_state + \" \"  # Initialize the story with the starting state\n",
    "\n",
    "    # Generate the story up to the word limit\n",
    "    while n < limit and curr_state in markov_model:\n",
    "        # Choose the next state based on the distribution in the Markov model\n",
    "        next_state = random.choices(\n",
    "            population=list(markov_model[curr_state].keys()),\n",
    "            weights=list(markov_model[curr_state].values()),\n",
    "            k=1  # Choose one next state\n",
    "        )[0]\n",
    "\n",
    "        story += next_state + \" \"  # Append the next state to the story\n",
    "        curr_state = next_state  # Update the current state to the next state\n",
    "        n += 1  # Increment word counter\n",
    "\n",
    "    return story.strip()  # Return the story, removing any trailing space\n",
    "\n",
    "# Example usage: Generate and print 20 short stories\n",
    "for i in range(20):\n",
    "    story = generate_story(markov_model=markov_model, start=\"dear holmes\", limit=8)\n",
    "    print(f\"{i}. {story}\")\n",
    "\n",
    "print(\"-------------------\")\n",
    "print(\"A longer story:\")\n",
    "print(generate_story(markov_model, start=\"the case\", limit=100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATACAMP example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The statespace\n",
    "states = [\"Sleep\",\"Icecream\",\"Run\"]\n",
    "\n",
    "# Possible sequences of events\n",
    "transitionName = [[\"SS\",\"SR\",\"SI\"],[\"RS\",\"RR\",\"RI\"],[\"IS\",\"IR\",\"II\"]]\n",
    "\n",
    "# Probabilities matrix (transition matrix)\n",
    "transitionMatrix = [[0.2,0.6,0.2],[0.1,0.6,0.3],[0.2,0.7,0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is gonna be okay, you should move on!! ;)\n"
     ]
    }
   ],
   "source": [
    "if sum(transitionMatrix[0]) + sum(transitionMatrix[1]) + sum(transitionMatrix[1]) != 3:\n",
    "    print(\"Somewhere, something went wrong. Transition matrix, perhaps?\")\n",
    "else: \n",
    "    print(\"All is gonna be okay, you should move on!! ;)\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start state: Sleep\n",
      "Possible states: ['Sleep', 'Run', 'Icecream']\n",
      "End state after 2 days: Icecream\n",
      "Probability of the possible sequence of states: 0.18\n"
     ]
    }
   ],
   "source": [
    "# A function that implements the Markov model to forecast the state/mood. \n",
    "def activity_forecast(days):\n",
    "    # Choose the starting state\n",
    "    activityToday = \"Sleep\"\n",
    "    print(\"Start state: \" + activityToday)\n",
    "    # Shall store the sequence of states taken. So, this only has the starting state for now.\n",
    "    activityList = [activityToday]\n",
    "    i = 0\n",
    "    # To calculate the probability of the activityList\n",
    "    prob = 1\n",
    "    while i != days:\n",
    "        if activityToday == \"Sleep\":\n",
    "            change = np.random.choice(transitionName[0],replace=True,p=transitionMatrix[0])\n",
    "            if change == \"SS\":\n",
    "                prob = prob * 0.2\n",
    "                activityList.append(\"Sleep\")\n",
    "                pass\n",
    "            elif change == \"SR\":\n",
    "                prob = prob * 0.6\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "            else:\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Run\":\n",
    "            change = np.random.choice(transitionName[1],replace=True,p=transitionMatrix[1])\n",
    "            if change == \"RR\":\n",
    "                prob = prob * 0.5\n",
    "                activityList.append(\"Run\")\n",
    "                pass\n",
    "            elif change == \"RS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else:\n",
    "                prob = prob * 0.3\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Icecream\":\n",
    "            change = np.random.choice(transitionName[2],replace=True,p=transitionMatrix[2])\n",
    "            if change == \"II\":\n",
    "                prob = prob * 0.1\n",
    "                activityList.append(\"Icecream\")\n",
    "                pass\n",
    "            elif change == \"IS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else: \n",
    "                prob = prob * 0.7\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "        i += 1  \n",
    "    print(\"Possible states: \" + str(activityList))\n",
    "    print(\"End state after \"+ str(days) + \" days: \" + activityToday)\n",
    "    print(\"Probability of the possible sequence of states: \" + str(prob))\n",
    "\n",
    "# Function that forecasts the possible state for the next 2 days\n",
    "activity_forecast(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skymantic",
   "language": "python",
   "name": "skymantics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
