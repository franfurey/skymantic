{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov Model Chain Python Example\n",
    "# https://www.datacamp.com/community/tutorials/markov-chains-python-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The statespace\n",
    "states = [\"Sleep\",\"Icecream\",\"Run\"]\n",
    "\n",
    "# Possible sequences of events\n",
    "transitionName = [[\"SS\",\"SR\",\"SI\"],[\"RS\",\"RR\",\"RI\"],[\"IS\",\"IR\",\"II\"]]\n",
    "\n",
    "# Probabilities matrix (transition matrix)\n",
    "transitionMatrix = [[0.2,0.6,0.2],[0.1,0.6,0.3],[0.2,0.7,0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is gonna be okay, you should move on!! ;)\n"
     ]
    }
   ],
   "source": [
    "if sum(transitionMatrix[0]) + sum(transitionMatrix[1]) + sum(transitionMatrix[1]) != 3:\n",
    "    print(\"Somewhere, something went wrong. Transition matrix, perhaps?\")\n",
    "else: \n",
    "    print(\"All is gonna be okay, you should move on!! ;)\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start state: Sleep\n",
      "Possible states: ['Sleep', 'Run', 'Icecream']\n",
      "End state after 2 days: Icecream\n",
      "Probability of the possible sequence of states: 0.18\n"
     ]
    }
   ],
   "source": [
    "# A function that implements the Markov model to forecast the state/mood. \n",
    "def activity_forecast(days):\n",
    "    # Choose the starting state\n",
    "    activityToday = \"Sleep\"\n",
    "    print(\"Start state: \" + activityToday)\n",
    "    # Shall store the sequence of states taken. So, this only has the starting state for now.\n",
    "    activityList = [activityToday]\n",
    "    i = 0\n",
    "    # To calculate the probability of the activityList\n",
    "    prob = 1\n",
    "    while i != days:\n",
    "        if activityToday == \"Sleep\":\n",
    "            change = np.random.choice(transitionName[0],replace=True,p=transitionMatrix[0])\n",
    "            if change == \"SS\":\n",
    "                prob = prob * 0.2\n",
    "                activityList.append(\"Sleep\")\n",
    "                pass\n",
    "            elif change == \"SR\":\n",
    "                prob = prob * 0.6\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "            else:\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Run\":\n",
    "            change = np.random.choice(transitionName[1],replace=True,p=transitionMatrix[1])\n",
    "            if change == \"RR\":\n",
    "                prob = prob * 0.5\n",
    "                activityList.append(\"Run\")\n",
    "                pass\n",
    "            elif change == \"RS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else:\n",
    "                prob = prob * 0.3\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Icecream\":\n",
    "            change = np.random.choice(transitionName[2],replace=True,p=transitionMatrix[2])\n",
    "            if change == \"II\":\n",
    "                prob = prob * 0.1\n",
    "                activityList.append(\"Icecream\")\n",
    "                pass\n",
    "            elif change == \"IS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else: \n",
    "                prob = prob * 0.7\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "        i += 1  \n",
    "    print(\"Possible states: \" + str(activityList))\n",
    "    print(\"End state after \"+ str(days) + \" days: \" + activityToday)\n",
    "    print(\"Probability of the possible sequence of states: \" + str(prob))\n",
    "\n",
    "# Function that forecasts the possible state for the next 2 days\n",
    "activity_forecast(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sherlock Holmes Example ussing Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/franciscofurey/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines =  215021\n",
      "Number of words =  2332247\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the directory containing the stories.\n",
    "story_path = './data/sherlock/sherlock/'\n",
    "\n",
    "def read_all_stories(story_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Reads all text files from a specified directory, stopping at a delimiter or an empty line.\n",
    "    \n",
    "    Parameters:\n",
    "        story_path (str): The path to the directory containing story files.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of lines from all files, excluding delimiter lines and empty lines.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for _, _, files in os.walk(story_path):\n",
    "        for file in files:\n",
    "            with open(os.path.join(story_path, file)) as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line == '----------': break\n",
    "                    if line:\n",
    "                        lines.append(line)\n",
    "    return lines\n",
    "        \n",
    "stories = read_all_stories(story_path=story_path)\n",
    "print(\"Number of lines = \", len(stories))\n",
    "\n",
    "def clean_txt(txt: list) -> list:\n",
    "    \"\"\"\n",
    "    Cleans a list of text lines by converting to lowercase, removing punctuation, and tokenizing.\n",
    "    \n",
    "    Parameters:\n",
    "        txt (list): A list of text lines to be cleaned.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of cleaned and tokenized words.\n",
    "    \"\"\"\n",
    "    cleaned_words = []\n",
    "    for line in txt:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\\\[\\]]\", \"\", line)\n",
    "        tokens = word_tokenize(line)\n",
    "        # Filter out tokens that are not alphabetic\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_words += words\n",
    "    return cleaned_words\n",
    "\n",
    "cleaned_stories = clean_txt(txt=stories)\n",
    "print(\"Number of words = \", len(cleaned_stories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states =  208717\n",
      "All possible transitions from 'the game' state: \n",
      "\n",
      "{'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'was afoot': 0.036036036036036036, 'for the': 0.036036036036036036, 'was whist': 0.036036036036036036, 'would have': 0.036036036036036036, 'in their': 0.036036036036036036, 'was up': 0.09009009009009009, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'is afoot': 0.036036036036036036, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703, 'your letter': 0.02702702702702703}\n"
     ]
    }
   ],
   "source": [
    "def make_markov_model(cleaned_stories: list, n_gram: int = 2) -> dict:\n",
    "    \"\"\"\n",
    "    Constructs a Markov model from a list of words.\n",
    "\n",
    "    This function creates a dictionary representing the transitions between n-gram states\n",
    "    to the next possible states along with their probabilities.\n",
    "\n",
    "    Parameters:\n",
    "        cleaned_stories (list): A list of cleaned and tokenized words from stories.\n",
    "        n_gram (int): The number of words in the state used for the Markov model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the Markov model where keys are current states\n",
    "              and values are dictionaries of next possible states and their probabilities.\n",
    "    \"\"\"\n",
    "    markov_model = {}  # Initialize an empty dictionary for the Markov model\n",
    "\n",
    "    # Loop through the list of words to populate the Markov model\n",
    "    for i in range(len(cleaned_stories) - n_gram - 1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        # Construct the current and next state by concatenating words\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]  # Remove the trailing space\n",
    "        next_state = next_state[:-1]\n",
    "\n",
    "        # If the current state is not in the model, add it\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {next_state: 1}\n",
    "        else:\n",
    "            # If the next state exists, increment; otherwise, add it with a count of 1\n",
    "            markov_model[curr_state].setdefault(next_state, 0)\n",
    "            markov_model[curr_state][next_state] += 1\n",
    "    \n",
    "    # Calculate transition probabilities for each state\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count / total  # Convert counts to probabilities\n",
    "        \n",
    "    return markov_model\n",
    "\n",
    "# Example usage\n",
    "markov_model = make_markov_model(cleaned_stories=cleaned_stories)\n",
    "print(\"Number of states = \", len(markov_model.keys()))\n",
    "print(\"All possible transitions from 'the game' state: \\n\")\n",
    "if 'the game' in markov_model:\n",
    "    print(markov_model['the game'])\n",
    "else:\n",
    "    print(\"The state 'the game' does not exist in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. dear holmes if i had known ralph smith who went to the mystery in the matter as a\n",
      "1. dear holmes i have it here in my heart for the test with me now and so atone\n",
      "2. dear holmes am i he gazed from sir charles for several days in bed and we may now\n",
      "3. dear holmes am i to do the theorizing what sort of proposal is that i never wanted anything\n",
      "4. dear holmes i thought it was clear enough against you for this one excursion he spent his days\n",
      "5. dear holmes that i am still at a small wayside station and it has sworn to his identity\n",
      "6. dear holmes i thought he was telling them that there can be handed out in an instant and\n",
      "7. dear holmes am i a wandering american with a wonderful worker if i pay him well certainly that\n",
      "8. dear holmes he has been quite long enough for me to execute this said baynes what do you\n",
      "9. dear holmes my previous letters and supposing that this unhappy lady to whom he observed if i remember\n",
      "10. dear holmes said i nodding towards my house i wont listen to this you can do with a\n",
      "11. dear holmes that i am rather shaken by that sound upon the fishes let me see the inside\n",
      "12. dear holmes he has seen too much not to know the kindly charitable good old governor how could\n",
      "13. dear holmes that i was able with a drawn face uncertain whether he should be away all day\n",
      "14. dear holmes i thought of the man whom we were told that they once were great comrades before\n",
      "15. dear holmes it is one of them drove down with me you shall hear the last to pass\n",
      "16. dear holmes if i can to give you these results you are a woman a little to one\n",
      "17. dear holmes i thought it as short as the two things together fairly turned my brain a commissionaire\n",
      "18. dear holmes what do you make such amends as you see me touch your money afterwards if you\n",
      "19. dear holmes i thought i should be exceedingly valuable to us it is the matter with me now\n",
      "-------------------\n",
      "A longer story:\n",
      "the case of the hall was a mere whim at first developed into a where an exceedingly unkempt and agitated elderly man strode out of our visitors stick since we are to ask the inspector to the youngest constable who wouldnt be glad to consider it has rankled in his innocence and who have been good enough to convince me that someone crept up to the yes i am determined well i had no intention of going to his relative lord you have heard it is very well he is indeed the mazarin stone it was before i met him hastening from his room for she is quite a size larger than any which he may have read that a distinguished career lay before the reader to exactly identify the dead man he enters port said he chuckling to himself his instincts would have brought us to the south it brought me here how has your business been attended to in your hands if he gave an exclamation of astonishment and of fear that some evil fish over our side holmes was distinguished in an incoherent and as he looked across at the familiar attitude i knew that night that i had\n"
     ]
    }
   ],
   "source": [
    "def generate_story(markov_model: dict, limit: int = 100, start: str = 'my god') -> str:\n",
    "    \"\"\"\n",
    "    Generates a story based on a given Markov model, starting from a specified state.\n",
    "\n",
    "    Parameters:\n",
    "        markov_model (dict): The Markov model to use for generating the story.\n",
    "        limit (int): The maximum number of words in the generated story.\n",
    "        start (str): The starting state (words) for the story.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the generated story.\n",
    "    \"\"\"\n",
    "    n = 0  # Initialize word counter\n",
    "    curr_state = start  # Set the current state to the starting words\n",
    "    story = curr_state + \" \"  # Initialize the story with the starting state\n",
    "\n",
    "    # Generate the story up to the word limit\n",
    "    while n < limit and curr_state in markov_model:\n",
    "        # Choose the next state based on the distribution in the Markov model\n",
    "        next_state = random.choices(\n",
    "            population=list(markov_model[curr_state].keys()),\n",
    "            weights=list(markov_model[curr_state].values()),\n",
    "            k=1  # Choose one next state\n",
    "        )[0]\n",
    "\n",
    "        story += next_state + \" \"  # Append the next state to the story\n",
    "        curr_state = next_state  # Update the current state to the next state\n",
    "        n += 1  # Increment word counter\n",
    "\n",
    "    return story.strip()  # Return the story, removing any trailing space\n",
    "\n",
    "# Example usage: Generate and print 20 short stories\n",
    "for i in range(20):\n",
    "    story = generate_story(markov_model=markov_model, start=\"dear holmes\", limit=8)\n",
    "    print(f\"{i}. {story}\")\n",
    "\n",
    "print(\"-------------------\")\n",
    "print(\"A longer story:\")\n",
    "print(generate_story(markov_model, start=\"the case\", limit=100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skymantic",
   "language": "python",
   "name": "skymantics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
