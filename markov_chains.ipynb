{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/franciscofurey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State representation\n",
    "def get_states() -> dict:\n",
    "    \"\"\"Return the mapping of state indices to state names.\"\"\"\n",
    "    return {\n",
    "        0: \"Burger\",\n",
    "        1: \"Pizza\",\n",
    "        2: \"Hotdog\"\n",
    "    }\n",
    "\n",
    "# Transition Matrix\n",
    "def get_transition_matrix() -> np.ndarray:\n",
    "    \"\"\"Return the transition matrix A.\"\"\"\n",
    "    return np.array([[0.2, 0.6, 0.2], [0.3, 0.0, 0.7], [0.5, 0.0, 0.5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(start_state: int, steps: int) -> None:\n",
    "    \"\"\"Perform a random walk on the Markov chain given a start state and number of steps.\"\"\"\n",
    "    A = get_transition_matrix()\n",
    "    state = get_states()\n",
    "    curr_state = start_state\n",
    "    print(state[curr_state], \"--->\", end=\" \")\n",
    "\n",
    "    while steps - 1:\n",
    "        curr_state = np.random.choice([0, 1, 2], p=A[curr_state])\n",
    "        print(state[curr_state], \"--->\", end=\" \")\n",
    "        steps -= 1\n",
    "    print(\"stop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(start_state: int, steps: int) -> None:\n",
    "    \"\"\"Estimate steady state probabilities using the Monte Carlo approach.\"\"\"\n",
    "    A = get_transition_matrix()\n",
    "    curr_state = start_state\n",
    "    pi = np.array([0, 0, 0])\n",
    "    pi[start_state] = 1\n",
    "\n",
    "    for i in range(steps):\n",
    "        curr_state = np.random.choice([0, 1, 2], p=A[curr_state])\n",
    "        pi[curr_state] += 1\n",
    "\n",
    "    print(\"π = \", pi / steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_matrix_multiplication(steps: int) -> None:\n",
    "    \"\"\"Calculate steady state probabilities using repeated matrix multiplication.\"\"\"\n",
    "    A = get_transition_matrix()\n",
    "    A_n = A\n",
    "\n",
    "    for i in range(steps):\n",
    "        A_n = np.matmul(A_n, A)\n",
    "\n",
    "    print(\"A^n = \\n\", A_n, \"\\n\")\n",
    "    print(\"π = \", A_n[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_left_eigen_vectors() -> None:\n",
    "    \"\"\"Find and display left eigen vectors and their normalized steady state probabilities.\"\"\"\n",
    "    A = get_transition_matrix()\n",
    "    values, left = scipy.linalg.eig(A, right=False, left=True)\n",
    "\n",
    "    print(\"left eigen vectors = \\n\", left, \"\\n\")\n",
    "    print(\"eigen values = \\n\", values)\n",
    "\n",
    "    pi = left[:, 0]\n",
    "    pi_normalized = [(x / np.sum(pi)).real for x in pi]\n",
    "    print(\"Normalized π = \", pi_normalized)\n",
    "    return pi_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prob(seq: list, A: np.ndarray, pi: list) -> float:\n",
    "    \"\"\"Calculate the probability of a given sequence of states.\"\"\"\n",
    "    start_state = seq[0]\n",
    "    prob = pi[start_state]\n",
    "    prev_state = start_state\n",
    "    for i in range(1, len(seq)):\n",
    "        curr_state = seq[i]\n",
    "        prob *= A[prev_state][curr_state]\n",
    "        prev_state = curr_state\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burger ---> Pizza ---> Hotdog ---> Hotdog ---> Burger ---> Pizza ---> Burger ---> Pizza ---> Hotdog ---> Hotdog ---> Burger ---> Pizza ---> Burger ---> Pizza ---> Burger ---> stop\n",
      "π =  [0.351911 0.210957 0.437133]\n",
      "A^n = \n",
      " [[0.35211268 0.21126761 0.43661972]\n",
      " [0.35211268 0.21126761 0.43661972]\n",
      " [0.35211268 0.21126761 0.43661972]] \n",
      "\n",
      "π =  [0.35211268 0.21126761 0.43661972]\n",
      "left eigen vectors = \n",
      " [[-0.58746336+0.j         -0.16984156-0.35355339j -0.16984156+0.35355339j]\n",
      " [-0.35247801+0.j          0.67936622+0.j          0.67936622-0.j        ]\n",
      " [-0.72845456+0.j         -0.50952467+0.35355339j -0.50952467-0.35355339j]] \n",
      "\n",
      "eigen values = \n",
      " [ 1.  +0.j        -0.15+0.3122499j -0.15-0.3122499j]\n",
      "Normalized π =  [0.3521126760563379, 0.2112676056338029, 0.43661971830985913]\n",
      "Sequence Probability:  0.036971830985915506\n"
     ]
    }
   ],
   "source": [
    "# Initial setup\n",
    "states = get_states()\n",
    "transition_matrix = get_transition_matrix()\n",
    "\n",
    "# Perform a random walk\n",
    "random_walk(start_state=0, steps=15)\n",
    "\n",
    "# Monte Carlo approach\n",
    "monte_carlo(start_state=0, steps=10**6)\n",
    "\n",
    "# Repeated matrix multiplication\n",
    "repeated_matrix_multiplication(steps=10**3)\n",
    "\n",
    "# Find left eigen vectors and their normalized steady state probabilities\n",
    "pi_normalized = find_left_eigen_vectors()\n",
    "\n",
    "# Calculate probability for a sequence\n",
    "sequence_prob = find_prob(seq=[1, 2, 2, 0], A=transition_matrix, pi=pi_normalized)\n",
    "print(\"Sequence Probability: \", sequence_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The statespace\n",
    "states = [\"Sleep\",\"Icecream\",\"Run\"]\n",
    "\n",
    "# Possible sequences of events\n",
    "transitionName = [[\"SS\",\"SR\",\"SI\"],[\"RS\",\"RR\",\"RI\"],[\"IS\",\"IR\",\"II\"]]\n",
    "\n",
    "# Probabilities matrix (transition matrix)\n",
    "transitionMatrix = [[0.2,0.6,0.2],[0.1,0.6,0.3],[0.2,0.7,0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is gonna be okay, you should move on!! ;)\n"
     ]
    }
   ],
   "source": [
    "if sum(transitionMatrix[0]) + sum(transitionMatrix[1]) + sum(transitionMatrix[1]) != 3:\n",
    "    print(\"Somewhere, something went wrong. Transition matrix, perhaps?\")\n",
    "else: \n",
    "    print(\"All is gonna be okay, you should move on!! ;)\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start state: Sleep\n",
      "Possible states: ['Sleep', 'Run', 'Icecream']\n",
      "End state after 2 days: Icecream\n",
      "Probability of the possible sequence of states: 0.18\n"
     ]
    }
   ],
   "source": [
    "# A function that implements the Markov model to forecast the state/mood. \n",
    "def activity_forecast(days):\n",
    "    # Choose the starting state\n",
    "    activityToday = \"Sleep\"\n",
    "    print(\"Start state: \" + activityToday)\n",
    "    # Shall store the sequence of states taken. So, this only has the starting state for now.\n",
    "    activityList = [activityToday]\n",
    "    i = 0\n",
    "    # To calculate the probability of the activityList\n",
    "    prob = 1\n",
    "    while i != days:\n",
    "        if activityToday == \"Sleep\":\n",
    "            change = np.random.choice(transitionName[0],replace=True,p=transitionMatrix[0])\n",
    "            if change == \"SS\":\n",
    "                prob = prob * 0.2\n",
    "                activityList.append(\"Sleep\")\n",
    "                pass\n",
    "            elif change == \"SR\":\n",
    "                prob = prob * 0.6\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "            else:\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Run\":\n",
    "            change = np.random.choice(transitionName[1],replace=True,p=transitionMatrix[1])\n",
    "            if change == \"RR\":\n",
    "                prob = prob * 0.5\n",
    "                activityList.append(\"Run\")\n",
    "                pass\n",
    "            elif change == \"RS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else:\n",
    "                prob = prob * 0.3\n",
    "                activityToday = \"Icecream\"\n",
    "                activityList.append(\"Icecream\")\n",
    "        elif activityToday == \"Icecream\":\n",
    "            change = np.random.choice(transitionName[2],replace=True,p=transitionMatrix[2])\n",
    "            if change == \"II\":\n",
    "                prob = prob * 0.1\n",
    "                activityList.append(\"Icecream\")\n",
    "                pass\n",
    "            elif change == \"IS\":\n",
    "                prob = prob * 0.2\n",
    "                activityToday = \"Sleep\"\n",
    "                activityList.append(\"Sleep\")\n",
    "            else: \n",
    "                prob = prob * 0.7\n",
    "                activityToday = \"Run\"\n",
    "                activityList.append(\"Run\")\n",
    "        i += 1  \n",
    "    print(\"Possible states: \" + str(activityList))\n",
    "    print(\"End state after \"+ str(days) + \" days: \" + activityToday)\n",
    "    print(\"Probability of the possible sequence of states: \" + str(prob))\n",
    "\n",
    "# Function that forecasts the possible state for the next 2 days\n",
    "activity_forecast(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sherlock Holmes Example ussing Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/franciscofurey/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines =  215021\n",
      "Number of words =  2332247\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the directory containing the stories.\n",
    "story_path = './data/sherlock/sherlock/'\n",
    "\n",
    "def read_all_stories(story_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Reads all text files from a specified directory, stopping at a delimiter or an empty line.\n",
    "    \n",
    "    Parameters:\n",
    "        story_path (str): The path to the directory containing story files.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of lines from all files, excluding delimiter lines and empty lines.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for _, _, files in os.walk(story_path):\n",
    "        for file in files:\n",
    "            with open(os.path.join(story_path, file)) as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line == '----------': break\n",
    "                    if line:\n",
    "                        lines.append(line)\n",
    "    return lines\n",
    "        \n",
    "stories = read_all_stories(story_path=story_path)\n",
    "print(\"Number of lines = \", len(stories))\n",
    "\n",
    "def clean_txt(txt: list) -> list:\n",
    "    \"\"\"\n",
    "    Cleans a list of text lines by converting to lowercase, removing punctuation, and tokenizing.\n",
    "    \n",
    "    Parameters:\n",
    "        txt (list): A list of text lines to be cleaned.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of cleaned and tokenized words.\n",
    "    \"\"\"\n",
    "    cleaned_words = []\n",
    "    for line in txt:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\\\[\\]]\", \"\", line)\n",
    "        tokens = word_tokenize(line)\n",
    "        # Filter out tokens that are not alphabetic\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_words += words\n",
    "    return cleaned_words\n",
    "\n",
    "cleaned_stories = clean_txt(txt=stories)\n",
    "print(\"Number of words = \", len(cleaned_stories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states =  208717\n",
      "All possible transitions from 'the game' state: \n",
      "\n",
      "{'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'was afoot': 0.036036036036036036, 'for the': 0.036036036036036036, 'was whist': 0.036036036036036036, 'would have': 0.036036036036036036, 'in their': 0.036036036036036036, 'was up': 0.09009009009009009, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'is afoot': 0.036036036036036036, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703, 'your letter': 0.02702702702702703}\n"
     ]
    }
   ],
   "source": [
    "def make_markov_model(cleaned_stories: list, n_gram: int = 2) -> dict:\n",
    "    \"\"\"\n",
    "    Constructs a Markov model from a list of words.\n",
    "\n",
    "    This function creates a dictionary representing the transitions between n-gram states\n",
    "    to the next possible states along with their probabilities.\n",
    "\n",
    "    Parameters:\n",
    "        cleaned_stories (list): A list of cleaned and tokenized words from stories.\n",
    "        n_gram (int): The number of words in the state used for the Markov model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the Markov model where keys are current states\n",
    "              and values are dictionaries of next possible states and their probabilities.\n",
    "    \"\"\"\n",
    "    markov_model = {}  # Initialize an empty dictionary for the Markov model\n",
    "\n",
    "    # Loop through the list of words to populate the Markov model\n",
    "    for i in range(len(cleaned_stories) - n_gram - 1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        # Construct the current and next state by concatenating words\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]  # Remove the trailing space\n",
    "        next_state = next_state[:-1]\n",
    "\n",
    "        # If the current state is not in the model, add it\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {next_state: 1}\n",
    "        else:\n",
    "            # If the next state exists, increment; otherwise, add it with a count of 1\n",
    "            markov_model[curr_state].setdefault(next_state, 0)\n",
    "            markov_model[curr_state][next_state] += 1\n",
    "    \n",
    "    # Calculate transition probabilities for each state\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count / total  # Convert counts to probabilities\n",
    "        \n",
    "    return markov_model\n",
    "\n",
    "# Example usage\n",
    "markov_model = make_markov_model(cleaned_stories=cleaned_stories)\n",
    "print(\"Number of states = \", len(markov_model.keys()))\n",
    "print(\"All possible transitions from 'the game' state: \\n\")\n",
    "if 'the game' in markov_model:\n",
    "    print(markov_model['the game'])\n",
    "else:\n",
    "    print(\"The state 'the game' does not exist in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. dear holmes i fear that this second man that has to be in better form both mental and\n",
      "1. dear holmes that i should register and interject if i could have laughed when i realized it as\n",
      "2. dear holmes and tell her that he loved but the path ran right on to kilburn there was\n",
      "3. dear holmes he has had his love but now i asked he has given us a yellow bar\n",
      "4. dear holmes am i sir he wasnt a dead man i heard a cry and supported himself against\n",
      "5. dear holmes i ejaculated as a child but when chance threw you in my thoughts standing there on\n",
      "6. dear holmes i ejaculated my dear holmes said he laying down his pipe and skipping over the pages\n",
      "7. dear holmes i fear a very stout portly man in the world for thoroughness and method of it\n",
      "8. dear holmes i have not seen this lonely silent house and the fury of the man blessington approached\n",
      "9. dear holmes i have as you have those ive been dreaming of the bright spring sunshine behind one\n",
      "10. dear holmes i ejaculated precisely so said mr holmes and youll get results inspector by always putting yourself\n",
      "11. dear holmes you are to ask you one of his kindness to him really does it really matter\n",
      "12. dear holmes what do you make of that smaller type which one may sink and with the aid\n",
      "13. dear holmes he has and where little tonga who shot him then ill get down to mr beddoes\n",
      "14. dear holmes if i were a hidden meaning in it is not purposeless who is it i handed\n",
      "15. dear holmes my previous letters and is now good heavens holmes this man collects women and that he\n",
      "16. dear holmes if i backed down i knew this young man out of the second stain not corresponding\n",
      "17. dear holmes i thought i drove home to the perpetrators for some years the bulwark of britain vast\n",
      "18. dear holmes it is a perfectly trivial one he jerked his arms folded and dry so that it\n",
      "19. dear holmes i exclaimed i could hardly believe my own rooms in his large straggling house the vicar\n",
      "-------------------\n",
      "A longer story:\n",
      "the case as they had done very well that the earl of maynooth at that time i emerged as you what happened was this about six feet broad on either side of a distant plantation and saw you coming downstairs on which the heavy stick which our visitor again passed his hand and gave mr sherlock holmes was always of opinion that this would be in time to take a magnifying glass to see one of our women on to other topics but it was so pale but i told her so and as old as is the escaped convict upon the succession exactly this chance of putting a humble mrcs and a man of action no sir i have not noticed them for every step that i thought it necessary to the councils of his comrades but was secretly horrified by my first impulse was of course it is an error to argue with him perhaps it was some strange swirl or eddy it was concerned with a will of iron it is a danger signal there he goes he would try by a few footmarks and the tyre of his doings of mr sherlock holmes the recital of our adventures\n"
     ]
    }
   ],
   "source": [
    "def generate_story(markov_model: dict, limit: int = 100, start: str = 'my god') -> str:\n",
    "    \"\"\"\n",
    "    Generates a story based on a given Markov model, starting from a specified state.\n",
    "\n",
    "    Parameters:\n",
    "        markov_model (dict): The Markov model to use for generating the story.\n",
    "        limit (int): The maximum number of words in the generated story.\n",
    "        start (str): The starting state (words) for the story.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the generated story.\n",
    "    \"\"\"\n",
    "    n = 0  # Initialize word counter\n",
    "    curr_state = start  # Set the current state to the starting words\n",
    "    story = curr_state + \" \"  # Initialize the story with the starting state\n",
    "\n",
    "    # Generate the story up to the word limit\n",
    "    while n < limit and curr_state in markov_model:\n",
    "        # Choose the next state based on the distribution in the Markov model\n",
    "        next_state = random.choices(\n",
    "            population=list(markov_model[curr_state].keys()),\n",
    "            weights=list(markov_model[curr_state].values()),\n",
    "            k=1  # Choose one next state\n",
    "        )[0]\n",
    "\n",
    "        story += next_state + \" \"  # Append the next state to the story\n",
    "        curr_state = next_state  # Update the current state to the next state\n",
    "        n += 1  # Increment word counter\n",
    "\n",
    "    return story.strip()  # Return the story, removing any trailing space\n",
    "\n",
    "# Example usage: Generate and print 20 short stories\n",
    "for i in range(20):\n",
    "    story = generate_story(markov_model=markov_model, start=\"dear holmes\", limit=8)\n",
    "    print(f\"{i}. {story}\")\n",
    "\n",
    "print(\"-------------------\")\n",
    "print(\"A longer story:\")\n",
    "print(generate_story(markov_model, start=\"the case\", limit=100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second example of Normalized Nerd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skymantic",
   "language": "python",
   "name": "skymantics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
